# üçä Detec√ß√£o de Laranjas em Laranjeiras: SSD MobileNet V2 (Trabalho de Mestrado)

Este reposit√≥rio documenta o trabalho de mestrado sobre a **Detec√ß√£o de Laranjas usando Single-Shot Multibox Detector com Arquitetura MobileNet V2 (SSDLite)**. [cite_start]O projeto tem como objetivo substituir os m√©todos manuais de contagem de frutos (como a derri√ßa) por uma ferramenta mais **r√°pida, barata e eficaz** para a estimativa da safra anual[cite: 34].

[cite_start]O trabalho foi desenvolvido na **Universidade Estadual de Campinas (UNICAMP)** [cite: 3] [cite_start]no Instituto de Matem√°tica, Estat√≠stica e Computa√ß√£o Cient√≠fica (IMECC)[cite: 7].

## ‚ö†Ô∏è Aviso Importante sobre os Dados

[cite_start]O banco de dados de **3028 imagens** de dimens√£o $(416 \times 416)$ [cite: 91] [cite_start]foi fornecido pelo **Fundecitrus** (Fundo de Defesa da Citricultura) [cite: 90] e n√£o pode ser distribu√≠do.

**Voc√™ est√° livre para usar toda a metodologia e o c√≥digo** aqui presente para aplicar a detec√ß√£o de objetos em seus pr√≥prios conjuntos de dados (outras frutas, objetos, etc.). [cite_start]As configura√ß√µes de treinamento foram otimizadas e podem ser um excelente ponto de partida para outros projetos[cite: 468].

* [cite_start]**Contato:** m.chiqueto@usp.br (E-mail USP) / m264864@dac.unicamp.br [cite: 6]

---

## üöÄ Resultados e Desempenho

[cite_start]O modelo **SSDLite (MobileNetV2)** demonstrou um √≥timo desempenho, superando o modelo SSD tradicional (com VGG) e apresentando um custo computacional muito baixo[cite: 467].

| Modelo | AP@0.5 | Par√¢metros | Tamanho do Modelo |
| :--- | :--- | :--- | :--- |
| **SSDLite (MobileNetV2)** | **0.88** | 4 M | **4,8 MB** |
| SSD (VGG) | 0.814 | 27 M | 182 MB |

[cite_start]*Tabela: Compara√ß√£o entre SSDLite e SSD VGG (adaptada da Apresenta√ß√£o)[cite: 444].*

**Destaques da Performance:**

* [cite_start]**Precis√£o:** O valor final de $AP@0.5 = 0.88$ indica um √≥timo desempenho de detec√ß√£o[cite: 418].
* [cite_start]**Efici√™ncia:** O modelo final exige apenas **4,8 MB** de mem√≥ria, o que viabiliza seu uso em dispositivos m√≥veis e permite treinamento com outros bancos de dados sem grandes requisitos de processamento[cite: 468].
* [cite_start]**Desafio:** O desempenho em **objetos pequenos** foi relativamente baixo em compara√ß√£o com objetos m√©dios e grandes, com $AP@Small$ com valor m√°ximo em torno de $0.4$[cite: 419, 420].

---

## üíª Metodologia de Detec√ß√£o

### 1. Arquitetura da Rede (MobileNet V2)

[cite_start]O trabalho utilizou o detector **SSD** com o extrator de caracter√≠sticas **MobileNet V2**[cite: 55].

* [cite_start]**Convolu√ß√µes Separ√°veis Profundas:** A caracter√≠stica mais distintiva da MobileNetV2 √© o uso de blocos residuais invertidos com gargalo linear[cite: 227].
* [cite_start]**Desenvolvimento:** A MobileNet V2 foi desenvolvida especificamente para dispositivos m√≥veis[cite: 229].

### 2. Configura√ß√£o do Treinamento

* [cite_start]**Transfer√™ncia de Aprendizado:** Os pesos da rede foram inicializados com aqueles da MobileNet V2 treinada com o banco de dados Microsoft COCO[cite: 402].
* [cite_start]**Regulariza√ß√£o:** Foram usadas t√©cnicas de regulariza√ß√£o, incluindo `dropout` e Regulariza√ß√£o de Tikhonov[cite: 403].
* [cite_start]**Aumento de Dados:** Aplica√ß√£o de **"Corte Aleat√≥rio"** e **"Espelhamento Horizontal"** para gerar imagens de treinamento[cite: 404, 405].
* [cite_start]**Fun√ß√£o Custo:** A perda total √© dada pela soma ponderada da perda de classifica√ß√£o ($L_{conf}$) e a perda de localiza√ß√£o ($L_{loc}$)[cite: 341].
    $$L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))$$
    * [cite_start]$L_{loc}$ √© baseada na fun√ß√£o Smooth-$L_{1}$[cite: 350].
    * [cite_start]$L_{conf}$ √© a Softmax sobre as $c$ classes[cite: 360].

---

### Passos Chave (Resumo do C√≥digo)

1.  **Prepara√ß√£o:** Instalar as depend√™ncias, clonar o reposit√≥rio `tensorflow/models` e montar o Drive.
2.  **Dados:** Adicione **suas pr√≥prias imagens** e anota√ß√µes na estrutura `data/`. Execute a convers√£o `xml_to_csv` e a cria√ß√£o dos `.record` e `label_map.pbtxt`.
3.  **Configura√ß√£o:** Baixar o modelo pr√©-treinado (e.g., `ssd_mobilenet_v2_320x320_coco17_tpu-8`) e editar o arquivo `.config` para apontar os caminhos corretos para os seus arquivos.
4.  **Treinamento:** Execute o `model_main_tf2.py`:
    ```bash
    !python /mydrive/Object_Detection/ssd/models/research/object_detection/model_main_tf2.py \
        --pipeline_config_path={pipeline_config} \
        --model_dir={model_dir_config} \
        --alsologtostderr \
        --eval_on_train_data=True
    ```
5.  **Exporta√ß√£o:** Exporte o `saved_model` final, utilizando o √∫ltimo *checkpoint* treinado, para obter o modelo final de infer√™ncia.

---

Se tiver d√∫vidas sobre a implementa√ß√£o, sinta-se √† vontade para entrar em contato atrav√©s do e-mail m.chiqueto@usp.br.
